{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702cb102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this notebook depends on a csv produced in R, gps_grid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, requests # for downloading power data with `dl_power_data()`\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time # for sleep\n",
    "\n",
    "from dataG2F.qol import *\n",
    "\n",
    "writeout_power_npys = False\n",
    "writeout_gps_grid = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '../nbs_artifacts/06_gps_grid_nasa_power/'\n",
    "ensure_dir_path_exists(dir_path = cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change gps_grid import to a location in data_ext; Do this after moving the R project into data_ext\n",
    "gps_grid = pd.read_csv('../data_ext/'+'gps_grid.csv').drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == False:\n",
    "    #Create the map\n",
    "    my_map = folium.Map(location = [38.928745, -92.352163], # LatLon\n",
    "                        zoom_start = 4)\n",
    "\n",
    "    for i in gps_grid.index:\n",
    "        e = list(gps_grid.loc[i, [\n",
    "            'state', \n",
    "            'lat', \n",
    "            'lon']])\n",
    "\n",
    "        # check for nas\n",
    "        if 0 in [1 if ee == ee else 0 for ee in e]:\n",
    "            print(e[0]+' contains missing values!')\n",
    "        else:\n",
    "            folium.Marker((e[1], e[2]), \n",
    "                          popup = e[0], \n",
    "                         ).add_to(my_map)\n",
    "\n",
    "    my_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb500a",
   "metadata": {},
   "source": [
    "## Download and Prep NASA Power Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425180c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from 01.02_g2fc_imputation.ipynb\n",
    "def dl_power_data(\n",
    "    latitude = 32.929, \n",
    "    longitude = -95.770,\n",
    "    start_YYYYMMDD = 20150101,\n",
    "    end_YYYYMMDD = 20150305\n",
    "):\n",
    "    # Modified by \n",
    "    # https://power.larc.nasa.gov/docs/tutorials/service-data-request/api/\n",
    "    '''\n",
    "    *Version: 2.0 Published: 2021/03/09* Source: [NASA POWER](https://power.larc.nasa.gov/)\n",
    "    POWER API Multi-Point Download\n",
    "    This is an overview of the process to request data from multiple data points from the POWER API.\n",
    "    '''\n",
    "\n",
    "    base_url = r\"https://power.larc.nasa.gov/api/temporal/daily/point?parameters=QV2M,T2MDEW,PS,RH2M,WS2M,GWETTOP,ALLSKY_SFC_SW_DWN,ALLSKY_SFC_PAR_TOT,T2M_MAX,T2M_MIN,T2MWET,GWETROOT,T2M,GWETPROF,ALLSKY_SFC_SW_DNI,PRECTOTCORR&community=RE&longitude={longitude}&latitude={latitude}&start={start_YYYYMMDD}&end={end_YYYYMMDD}&format=JSON\"\n",
    "\n",
    "    api_request_url = base_url.format(\n",
    "        longitude=longitude, \n",
    "        latitude=latitude,\n",
    "        start_YYYYMMDD=start_YYYYMMDD, \n",
    "        end_YYYYMMDD=end_YYYYMMDD)\n",
    "\n",
    "    response = requests.get(url=api_request_url, verify=True, timeout=30.00)\n",
    "\n",
    "    content = json.loads(response.content.decode('utf-8'))\n",
    "\n",
    "    # Repackage content as data frame\n",
    "    df_list = [\n",
    "        pd.DataFrame(content['properties']['parameter'][e], index = [0]).melt(\n",
    "        ).rename(columns = {'variable':'Date', 'value':e})\n",
    "        for e in list(content['properties']['parameter'].keys())\n",
    "    ]\n",
    "\n",
    "    for i in range(len(df_list)):\n",
    "        if i == 0:\n",
    "            out = df_list[i]\n",
    "        else:\n",
    "            out = out.merge(df_list[i])\n",
    "\n",
    "    out['Latitude'] = latitude\n",
    "    out['Longitude'] = longitude\n",
    "    first_cols = ['Latitude', 'Longitude', 'Date']\n",
    "    out = out.loc[:, first_cols+[e for e in list(out) if e not in first_cols]]\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bbc3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-80.408115</td>\n",
       "      <td>25.418081</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-80.905151</td>\n",
       "      <td>25.418081</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-80.465913</td>\n",
       "      <td>25.869427</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-80.964813</td>\n",
       "      <td>25.869427</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-81.463714</td>\n",
       "      <td>25.869427</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>-119.494095</td>\n",
       "      <td>48.844786</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>-120.175271</td>\n",
       "      <td>48.844786</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>-120.856447</td>\n",
       "      <td>48.844786</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>-121.537623</td>\n",
       "      <td>48.844786</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>-122.218800</td>\n",
       "      <td>48.844786</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat       state\n",
       "0     -80.408115  25.418081     Florida\n",
       "1     -80.905151  25.418081     Florida\n",
       "2     -80.465913  25.869427     Florida\n",
       "3     -80.964813  25.869427     Florida\n",
       "4     -81.463714  25.869427     Florida\n",
       "...          ...        ...         ...\n",
       "3117 -119.494095  48.844786  Washington\n",
       "3118 -120.175271  48.844786  Washington\n",
       "3119 -120.856447  48.844786  Washington\n",
       "3120 -121.537623  48.844786  Washington\n",
       "3121 -122.218800  48.844786  Washington\n",
       "\n",
       "[3122 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gps_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b31c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3122/3122 [00:00<00:00, 5362.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Download data and cache it.\n",
    "sleep_for = 1\n",
    "\n",
    "ensure_dir_path_exists(dir_path = cache_path+'power_data/')\n",
    "cached_files = os.listdir(cache_path+'power_data/')\n",
    "for i in tqdm(gps_grid.index):\n",
    "    lon, lat = gps_grid.loc[i, ['lon', 'lat']]\n",
    "    start_date = 19810101\n",
    "    end_date = 20221231\n",
    "    save_name = str(lon)+'_'+str(lat)+'_'+str(start_date)+'_'+str(end_date)+'.pkl'\n",
    "    \n",
    "    if save_name in cached_files:\n",
    "        pass\n",
    "    else:\n",
    "        if i != 0:\n",
    "            time.sleep(sleep_for)   \n",
    "            \n",
    "        res = dl_power_data(\n",
    "            latitude = lat, \n",
    "            longitude = lon,\n",
    "            start_YYYYMMDD = start_date,\n",
    "            end_YYYYMMDD = end_date\n",
    "        )\n",
    "\n",
    "        put_cached_result(cache_path+'power_data/'+save_name, res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f0ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-106.692895889282_43.8968753814697_19810101_20221231.pkl',\n",
       " '-70.6439685821533_44.3468856811523_19810101_20221231.pkl',\n",
       " '-111.489644050598_34.8897933959961_19810101_20221231.pkl',\n",
       " '-104.400300979614_40.2957248687744_19810101_20221231.pkl',\n",
       " '-80.8516311645508_37.5933933258057_19810101_20221231.pkl',\n",
       " '-77.9374122619629_40.2957248687744_19810101_20221231.pkl',\n",
       " '-109.246292114258_35.7911491394043_19810101_20221231.pkl',\n",
       " '-111.143846511841_37.1428489685059_19810101_20221231.pkl',\n",
       " '-121.814107894897_42.0966339111328_19810101_20221231.pkl',\n",
       " '-98.8756561279297_29.0279769897461_19810101_20221231.pkl']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load cached files and save into database\n",
    "cached_files = os.listdir(cache_path+'power_data/')\n",
    "cached_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# match files that look like pickled nasa power entries\n",
    "# '-106.692895889282_43.8968753814697_19810101_20221231.pkl',\n",
    "cached_files = [e for e in cached_files if re.match('^.\\d*\\.\\d*_\\d*\\.\\d*\\_\\d+\\_\\d*\\.pkl$', e)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class prep_power():\n",
    "    def __init__(self,\n",
    "                 power_path,\n",
    "                 power_files\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lats = []\n",
    "        self.lons = []\n",
    "        self.date = []\n",
    "        self.keys = []\n",
    "\n",
    "        expected_shape = None\n",
    "\n",
    "        res = pd.read_pickle(power_path+power_files[0])\n",
    "\n",
    "        res = res.sort_values('Date')\n",
    "        self.date = res.Date.to_list()\n",
    "        self.keys = [e for e in list(res) if e not in ['Latitude', 'Longitude', 'Date']]\n",
    "        \n",
    "        self.lats += [res.loc[0, 'Latitude']]\n",
    "        self.lons += [res.loc[0, 'Longitude']]\n",
    "\n",
    "        expected_shape = res.shape\n",
    "\n",
    "        # shape               entry,            channel,        date\n",
    "        self.data = np.zeros([len(power_files), len(self.keys), expected_shape[0]])\n",
    "\n",
    "        for i in tqdm(range(len(power_files))):\n",
    "            e = power_files[i]\n",
    "            # print(e)\n",
    "            res = pd.read_pickle(power_path+e)\n",
    "            if res.shape != expected_shape:\n",
    "                print(f'Problem with {e}')\n",
    "                self.data[i, :, :] = np.nan\n",
    "            else:\n",
    "                res = res.sort_values('Date')\n",
    "                self.data[i, :, :] = res.loc[:, self.keys].to_numpy().transpose()\n",
    "                self.lats += [res.loc[0, 'Latitude']]\n",
    "                self.lons += [res.loc[0, 'Longitude']]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd0e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3122/3122 [00:55<00:00, 56.24it/s]\n"
     ]
    }
   ],
   "source": [
    "if writeout_power_npys:\n",
    "    power = prep_power(\n",
    "        power_path  = cache_path+'power_data/',\n",
    "        power_files = cached_files\n",
    "        )\n",
    "\n",
    "    # write out numpy files\n",
    "    tmp = [\n",
    "        ['power_lats', np.array(power.lats)],\n",
    "        ['power_lons', np.array(power.lons)],\n",
    "        ['power_date', np.array(power.date)],\n",
    "        ['power_keys', np.array(power.keys)],\n",
    "        ['power_data',          power.data ],\n",
    "        ]\n",
    "    _ = [np.save(cache_path+f'power_data/{e[0]}.npy', e[1]) for e in tmp] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb9f49",
   "metadata": {},
   "source": [
    "## Get information to link GPS to County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_geocoder_data(\n",
    "    # note google maps uses lat/lon\n",
    "    longitude = -92.4562972,\n",
    "    latitude  = 38.9057937,\n",
    "    benchmark = 'Public_AR_Current',\n",
    "    vintage   = 'Current_Current'\n",
    "):\n",
    "    # https://geocoding.geo.census.gov/geocoder/Geocoding_Services_API.html\n",
    "    # https://geocoding.geo.census.gov/geocoder/geographies/coordinates\n",
    "    if benchmark != 'Public_AR_Current':\n",
    "        print(f'Mapping for {benchmark} is not defined!')\n",
    "    else:\n",
    "        benchmark = 4\n",
    "    if vintage  != 'Current_Current':\n",
    "        print(f'Mapping for {vintage} is not defined!')\n",
    "    else:\n",
    "        vintage  = 4\n",
    "\n",
    "    api_request_url = f'https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={longitude}&y={latitude}&benchmark={benchmark}&vintage={vintage}'\n",
    "    api_request_url = ''.join([\n",
    "        'https://geocoding.geo.census.gov/geocoder/geographies/coordinates?',\n",
    "        f'x={longitude}&y={latitude}',\n",
    "        f'&benchmark={benchmark}',\n",
    "        f'&vintage={vintage}',\n",
    "        '&format=json'\n",
    "    ])\n",
    "\n",
    "    response = requests.get(url=api_request_url, verify=True, timeout=30.00)\n",
    "\n",
    "    content = json.loads(response.content.decode('utf-8'))\n",
    "    return(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class geocoder_data():\n",
    "    def __init__(self,\n",
    "                 json_path\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, 'r') as fp:\n",
    "                data = json.load(fp)\n",
    "        else: \n",
    "            data = {\n",
    "                'lookup': {'longitude': [],\n",
    "                        'latitude': [],\n",
    "                        'idx': [],\n",
    "                        },\n",
    "                'data':[]\n",
    "                }\n",
    "            \n",
    "        self.data = data\n",
    "        self.json_path = json_path\n",
    "        if self.data['lookup']['idx'] == []:\n",
    "            self.next_idx = 0\n",
    "        else:\n",
    "            self.next_idx = 1+max(self.data['lookup']['idx'])\n",
    "\n",
    "    def entry_exists(self, longitude, latitude, return_idx = False):\n",
    "        for i, e in enumerate(zip(self.data['lookup']['longitude'],\n",
    "                                  self.data['lookup']['latitude'])):\n",
    "            if e == (longitude, latitude):\n",
    "                if return_idx:\n",
    "                    return i\n",
    "                else:\n",
    "                    return True\n",
    "        if return_idx:\n",
    "            return i\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def add_entry(self, longitude, latitude, overwrite = False):\n",
    "        if ((overwrite == False) & \n",
    "            (self.entry_exists(longitude = longitude, latitude = latitude) == True)):\n",
    "            pass\n",
    "        else:\n",
    "            res = dl_geocoder_data(\n",
    "                # note google maps uses lat/lon\n",
    "                longitude = longitude,\n",
    "                latitude  = latitude,\n",
    "                benchmark = 'Public_AR_Current',\n",
    "                vintage   = 'Current_Current'\n",
    "            )\n",
    "\n",
    "            self.data['lookup']['longitude'] += [longitude] \n",
    "            self.data['lookup']['latitude']  += [latitude]\n",
    "            self.data['lookup']['idx']       += [self.next_idx]\n",
    "\n",
    "            self.data['data'] += [res]\n",
    "\n",
    "            self.next_idx += 1\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.json_path, 'w') as f:\n",
    "            json.dump(self.data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # def add_entries(self, longitude_list, latitude_list, overwrite = False):\n",
    "    #     for i, e in zip(longitude_list, latitude_list):\n",
    "    #         lon, lat = e\n",
    "    #     self.add_entry(longitude = lon, latitude = lat, overwrite = overwrite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_dir_path_exists(dir_path = cache_path+'geocoder_data/')    \n",
    "\n",
    "gps_grid_geocoder = geocoder_data(json_path = cache_path+'geocoder_data/'+'gps2geocoder.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e9e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3122/3122 [1:26:18<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "save_every = 100\n",
    "sleep_for  = 2#0\n",
    "for i in tqdm(gps_grid.index):\n",
    "    lon = gps_grid.loc[i, 'lon']\n",
    "    lat = gps_grid.loc[i, 'lat']\n",
    "    # print(lon, lat)\n",
    "    next_i = gps_grid_geocoder.next_idx\n",
    "\n",
    "    gps_grid_geocoder.add_entry(\n",
    "        longitude = lon, \n",
    "        latitude = lat,\n",
    "    )\n",
    "    # only sleep if data was downloaded.\n",
    "    if next_i != gps_grid_geocoder.next_idx:\n",
    "        time.sleep(sleep_for)\n",
    "    \n",
    "    if save_every != None:\n",
    "        if ((i % save_every) == 0):\n",
    "            gps_grid_geocoder.save()\n",
    "gps_grid_geocoder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a433a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3122/3122 [00:00<00:00, 9093.63it/s] \n"
     ]
    }
   ],
   "source": [
    "# confirm that the order is as expected\n",
    "for i in tqdm(gps_grid.index):\n",
    "    lon = gps_grid.loc[i, 'lon']\n",
    "    lat = gps_grid.loc[i, 'lat']\n",
    "    j = gps_grid_geocoder.entry_exists(longitude= lon, latitude= lat, return_idx = True)\n",
    "    if i != j:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6410188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be able to go off of gps_grid.index but check against the lon/lat just in case\n",
    "def search_geocoder(geocoder = gps_grid_geocoder,\n",
    "                    longitude = gps_grid.lon.to_list()[0],\n",
    "                    latitude = gps_grid.lat.to_list()[0]\n",
    "                    ):\n",
    "    for e in zip(*[geocoder.data['lookup'][e] for e in ['longitude', 'latitude', 'idx']]):\n",
    "        if ((longitude == e[0]) & (latitude == e[1])):\n",
    "            return e[2]\n",
    "    return None\n",
    "\n",
    "\n",
    "gps_grid.loc[:, 'State'] = ''\n",
    "gps_grid.loc[:, 'StateAbr'] = ''\n",
    "gps_grid.loc[:, 'Counties'] = ''\n",
    "\n",
    "\n",
    "for i in gps_grid.index:\n",
    "    mask = (gps_grid.index == i)\n",
    "    lon = gps_grid.loc[mask, 'lon'].to_list()[0]\n",
    "    lat = gps_grid.loc[mask, 'lat'].to_list()[0]\n",
    "\n",
    "    # check for a matching index and then fill values\n",
    "    idx = search_geocoder(geocoder = gps_grid_geocoder, longitude = lon, latitude = lat)\n",
    "    if idx == None:\n",
    "        pass\n",
    "    else:\n",
    "        gps_grid.loc[mask, 'State'] = [\n",
    "            gps_grid_geocoder.data['data'][idx]['result']['geographies']['States'][0]['BASENAME']\n",
    "        ]\n",
    "        gps_grid.loc[mask, 'StateAbr'] = [\n",
    "            gps_grid_geocoder.data['data'][idx]['result']['geographies']['States'][0]['STUSAB'] \n",
    "        ]\n",
    "        gps_grid.loc[mask, 'Counties'] = [\n",
    "            gps_grid_geocoder.data['data'][idx]['result']['geographies']['Counties'][0]['NAME']\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b465c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>state</th>\n",
       "      <th>State</th>\n",
       "      <th>StateAbr</th>\n",
       "      <th>Counties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-80.408115</td>\n",
       "      <td>25.418081</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>FL</td>\n",
       "      <td>MIAMI-DADE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-80.905151</td>\n",
       "      <td>25.418081</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>FL</td>\n",
       "      <td>MONROE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-80.465913</td>\n",
       "      <td>25.869427</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>FL</td>\n",
       "      <td>MIAMI-DADE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-80.964813</td>\n",
       "      <td>25.869427</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>FL</td>\n",
       "      <td>COLLIER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-81.463714</td>\n",
       "      <td>25.869427</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>FL</td>\n",
       "      <td>COLLIER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>-119.494095</td>\n",
       "      <td>48.844786</td>\n",
       "      <td>Washington</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>WA</td>\n",
       "      <td>OKANOGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>-120.175271</td>\n",
       "      <td>48.844786</td>\n",
       "      <td>Washington</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>WA</td>\n",
       "      <td>OKANOGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>-120.856447</td>\n",
       "      <td>48.844786</td>\n",
       "      <td>Washington</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>WA</td>\n",
       "      <td>WHATCOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>-121.537623</td>\n",
       "      <td>48.844786</td>\n",
       "      <td>Washington</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>WA</td>\n",
       "      <td>WHATCOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>-122.218800</td>\n",
       "      <td>48.844786</td>\n",
       "      <td>Washington</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>WA</td>\n",
       "      <td>WHATCOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3122 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat       state       State StateAbr    Counties\n",
       "0     -80.408115  25.418081     Florida     FLORIDA       FL  MIAMI-DADE\n",
       "1     -80.905151  25.418081     Florida     FLORIDA       FL      MONROE\n",
       "2     -80.465913  25.869427     Florida     FLORIDA       FL  MIAMI-DADE\n",
       "3     -80.964813  25.869427     Florida     FLORIDA       FL     COLLIER\n",
       "4     -81.463714  25.869427     Florida     FLORIDA       FL     COLLIER\n",
       "...          ...        ...         ...         ...      ...         ...\n",
       "3117 -119.494095  48.844786  Washington  WASHINGTON       WA    OKANOGAN\n",
       "3118 -120.175271  48.844786  Washington  WASHINGTON       WA    OKANOGAN\n",
       "3119 -120.856447  48.844786  Washington  WASHINGTON       WA     WHATCOM\n",
       "3120 -121.537623  48.844786  Washington  WASHINGTON       WA     WHATCOM\n",
       "3121 -122.218800  48.844786  Washington  WASHINGTON       WA     WHATCOM\n",
       "\n",
       "[3122 rows x 6 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gps_grid = gps_grid.loc[(gps_grid['Counties'] != ''), ].reset_index(drop = True).copy()\n",
    "gps_grid.Counties = gps_grid.Counties.str.upper().str.replace(' COUNTY', '')\n",
    "gps_grid.State = gps_grid.State.str.upper()\n",
    "\n",
    "if writeout_gps_grid:\n",
    "    gps_grid.to_csv(cache_path+'latlon_to_county.csv')\n",
    "gps_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb9ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dac5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache_path+'power_data/'+cached_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef07b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "\n",
    "# for e in tqdm(cached_files):\n",
    "#     res = pd.read_pickle(cache_path+'power_data/'+e)\n",
    "#     with sqlite3.connect(cache_path+\"/power_gps_grid.sqlite\") as con:\n",
    "#         res.to_sql('data', con, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.read_pickle(cache_path+'power_data/'+cached_files[0])\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e2534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "\n",
    "# with sqlite3.connect(cache_path+\"/power_gps_grid.sqlite\") as con:\n",
    "#     res.to_sql('data', con, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80a79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = get_cached_result(cache_path+'power_data/'+'-80.9051513671875_25.4180812835693_19810101_20221231.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55564916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with sqlite3.connect(cache_path+\"/power_gps_grid.sqlite\") as con:\n",
    "#     res.to_sql('data', con, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b710d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with sqlite3.connect(cache_path+\"/g2f_comp.sqlite\") as con:\n",
    "#     phno.to_sql('phno', con, if_exists='replace')\n",
    "#     meta.to_sql('meta', con, if_exists='replace')\n",
    "#     soil.to_sql('soil', con, if_exists='replace')\n",
    "#     wthr.to_sql('wthr', con, if_exists='replace')\n",
    "#     cgmv.to_sql('cgmv', con, if_exists='replace')\n",
    "#     cmnt.to_sql('cmnt', con, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
